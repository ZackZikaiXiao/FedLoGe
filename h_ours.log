nohup: ignoring input
./temp/fl_acc_cifar100_resnet34_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N20_100_seed3407_p1_dirichlet1.0_IF0.01_LossCE.txt
Files already downloaded and verified
[500, 477, 455, 434, 415, 396, 378, 361, 344, 328, 314, 299, 286, 273, 260, 248, 237, 226, 216, 206, 197, 188, 179, 171, 163, 156, 149, 142, 135, 129, 123, 118, 112, 107, 102, 98, 93, 89, 85, 81, 77, 74, 70, 67, 64, 61, 58, 56, 53, 51, 48, 46, 44, 42, 40, 38, 36, 35, 33, 32, 30, 29, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 15, 14, 13, 13, 12, 12, 11, 11, 10, 10, 9, 9, 8, 8, 7, 7, 7, 6, 6, 6, 6, 5, 5, 5, 5]
10847
Files already downloaded and verified
Into non-iid sampling
clients_sizes:[496, 625, 562, 489, 532, 550, 584, 692, 545, 549, 522, 470, 575, 454, 619, 636, 549, 522, 377, 499]
training set distribution:
[[17 44  1 16 45 16  7  2  3 13  6  1 13 16 32  6  2  3 13 19  6 25  3  0
  20  5 11 35 12  4  4  0  6  5  0  6  3  3  4  0  0  1  2  5  0  1  3  1
   2  5  4  0  0  4  1  5  1  2  3  5  0  0  0  0  1  0  1  0  4  0  0  1
   1  0  0  0  2  1  0  0  0  4  2  1  0  0  1  0  1  0  0  1  1  0  0  1
   0  0  1  0]
 [37 35  4 11 50 16 31 29 24 48  1 40 18  1 12 42 15  2  3  4 14  9 12  2
   0 24  8  1  3  6  0  8  8 10  1  7  1  2  1  2  2  0  4  2  6  8  3  5
   0  0  2  1  1  6  1  3  3  4  0  0  1  0  0  2  3  0  1  2  7  2  0  2
   0  0  2  0  0  0  1  1  0  0  0  3  0  1  0  0  0  0  0  1  2  0  0  0
   1  0  0  0]
 [72 22 35 20  2  1  7 29  0  6  6  6 38  2 44  8 17 26  4  8  3  3 18  3
   3 13 15  1 21  4  1  9 10  3  1  7  1  1  2  7  0  5  1  3  1  8  0  0
   6  1  0  1  4  1  6  3  0  1  2  3  0  0  2  4  2  2  0  0  2  1  0  1
   0  2  0  0  0  0  1  0  5  2  0  0  0  1  0  1  0  3  2  0  3  1  0  0
   0  0  1  1]
 [59 40  5 11  0  8 18  0  6  7 19  0  1  1  6 14  9  2  2  2 34 30 33 11
  31  4 16  0  4  2  3  1 17  1 22  4  2  6  0  0 10  1  0  4  5  2  4  0
   1  6  1  0  0  0  0  1  2  0  0  1  1  2  0  5  1  0  3  0  0  0  2  0
   0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  2  0  0  0  0  0
   0  2  0  0]
 [21 21 33  3  1 20  1 23 15 31 73  9 47  4  2 21  2  5  8 14  7  3  7  2
   5  0 11  7  3  4  4  0  9  2  3 11  4  0  2  8  2  1 12  7  0  1  3  1
   4  4  0  1  6  1  4  4  0  2  0  7  1  0  1  0  1  1  1  1  0  0  1  3
   0  0  2  1  1  2  0  0  2  0  1  1  0  1  0  0  3  1  0  0  0  0  0  0
   0  0  0  1]
 [ 9  1 42  5  1 39  1  6 56 26 14  1 15  1 37  4 20  4  2  0  8  3  5  5
   0  7  7  1 17  8 19 20  0 15  6 14  0  0  0  6 14 19  2  4  7  3  2  4
   5  3  2  6  1  4  1  7  1  3  2  0  0  0  2  1  2  0  5  3  0  1  2  4
   2  1  1  0  2  0  0  1  0  0  0  0  0  0  1  5  0  0  1  0  0  0  0  0
   1  0  0  0]
 [25 32  9 15 42  7 91 17 16  6  0  8 21 15 13 19 18 24  9  1  7  2  2  3
  31  1  2  2 12 15  9  3 14  0  1  2  0  2 12  5  0  9  1  3  1  4  1  1
   4  7  3  0  2  2  0  0  1  0  1  2  2  6  0  4  1  0  0  0  3  3  0  0
   1  2  0  1  1  0  0  1  1  1  0  0  1  0  0  0  0  0  0  0  0  0  1  0
   0  0  0  0]
 [10 22 38 26 10 22 75 38 23 16  6  8  0 32 16 18 20  0  4 19 33 35  2 23
  23  3  6 14  3  8 10 15  1  8  2  1  6  8 23  1  6  5  7  4  7  0  7  0
   0  0  0  0  1  7  0  1  0  0  0  0  1  0  2  1  0  0  2  0  0  0  1  0
   0  0  0  1  0  6  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  2  0  0
   0  2  0  0]
 [24  6 21  2 11  8  0 25 32  3  1 27 22 59  6 32  9 13 47 14 10  0  4 17
  16  9  3  0  4  3  4  7  5  3  3  1 11  5  5  1  4  0  2  7  2  3  0  0
   5  3  3  8  0  0  0  0  2  3  0  1  1  6  4  3  0  2  0  1  0  0  1  0
   1  0  0  0  0  0  0  0  0  1  0  2  1  0  0  0  0  0  0  2  0  0  3  0
   0  0  1  0]
 [62 20 21  9 10 86  9 17 23  3  7  6  5 16  7  1  3 15  0  4  3  4 30  8
   2  4  3 12  0 22 10 12  6  2 14  1  0  4  3  7 16  0  0  2  0  8  7  1
   1  2 11  0  0  0  2  2  0  3  0  3  2  2  0  0  2  1  0  2  0  1  0  0
   3  1  0  1  0  0  0  0  0  2  0  0  0  1  0  0  0  2  0  0  0  0  0  0
   0  0  0  0]
 [23 56 14 32 72 38  7  3  0 13  9 19  1  7  3 18  5 16  5  5 36  2  7  0
   0  6  4  0  6  0 10 11  0 12  1  8  3  5  3  6  0  0  0  1  4  1  1  5
   1  1  1  5  3  1  2  2  0  0  0  6  1  1  0  0  4  2  0  0  0  0  3  0
   0  0  1  0  0  0  0  0  0  1  0  0  1  3  1  0  0  1  0  1  0  0  1  0
   1  0  0  0]
 [ 9 64 31 76  2  0  9  3 11 21 15  6  2 20  2  0  1  0 16  8  1  4  0  0
   4  3 17 13  2  0 22  1  8  1  2  0  0 10  3  3  1  2  7  8  1  6  1  3
   2  3  3  0  0  0  4  2  8  2  0  0  8  0  0  1  2  1  1  1  0  1  0  0
   1  0  0  0  1  0  2  3  0  0  0  1  0  1  0  0  0  0  0  0  0  1  0  2
   0  0  0  0]
 [10 15 59  8 44  1  8 70  2  1  2 38 19 20  3 14  0  6  9 37 14  4  3  1
   1 10 10  2  0  5 10  4  1  8  2  9  2 21  1  9  2  9  0  2  7  2  7  2
   5  4  3  4  7  0  2  0  1  1  6  3  1  1  0  0  1  1  0  1  0  5  0  1
   0  0  0  1  0  2  1  0  0  0  4  0  2  0  1  0  1  0  0  0  0  0  1  1
   0  0  0  0]
 [18 24 53  4  7  1 13 21 28  3  2 22 12 14  5 25  8  3  1 12  2  4 14 21
   3  0  2 15  4  6  0 11  2  1  5  1  8  7  5  0  3  0  0  3  3  0  0  3
   0  1  0  4  3  6  1  0  0  0  1  0  5  1  2  0  2  1  3  7  0  3  0  0
   0  5  0  2  1  0  0  0  2  0  0  0  0  0  0  1  1  0  0  1  0  1  0  0
   1  0  0  0]
 [ 1  5  2 43 54 13 45 26 33 18  0 14  0 11  4  3 32 45 24 13  7  5  5  4
   1 19 11 22 22  7  1  0  8 17  2 11  5  1  2  6  3  6  0  1  4  2  1  4
   2  1  2  3  7  1  0  5 11  0  5  0  1  0  0  1  0  1  2  1  0  0  0  1
   0  0  2  1  0  1  2  0  0  0  1  0  1  0  0  0  2  0  0  0  0  0  0  0
   1  0  1  0]
 [26  8  8  4  7  2 14 11 19 80 54 45 31 11 22  7  7  6 25  2  0  1  6 36
  14 31  0  4  6  6  1  5  3  7 11  0  8  5  4  4  0  3 11  4  1  4  1  5
   3  3  0  1  0  4  3  2  2  5  0  0  1  1 10  1  0  4  0  1  2  0  0  1
   1  5  3  4  4  0  0  1  1  0  1  0  0  0  0  1  0  0  0  0  0  1  0  0
   0  0  0  0]
 [57 21  3 84  9  7  0  5  1  0 21 13 23  3  3  1  0  9 41 39  2 33  3 19
   0  6  5  0  2  0  3  1  5  3  1 12  2  2  1  5  2  8 14  2  9  1  7 19
   1  0  4  1  1  5  0  0  0  6  5  0  0  0  3  0  1  1  3  0  0  0  2  0
   0  0  0  1  0  0  2  2  1  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [ 9 15 16 22  9 32  0 27 11 28 60 26  6 35  3 10 40 13  1  1  4 10 16  1
   3  9  1  1  6  2 11  4  4  6  6  1  6  2  1  1  0  0  0  2  6  0  0  0
   5  1  3  9  1  0  3  1  0  2  3  1  0  1  0  0  1  1  0  1  1  1  5  1
   5  0  3  1  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  3]
 [ 5 17 57 11  6 13  7  5  3  2  3  8  6  2 28  3 22  1  0  0  3 10  8  3
   1  0  0  3  0 26  1  3  1  1 19  0  9  0  2  9  2  2  6  1  0  5  1  2
   0  5  4  1  6  0  8  0  1  0  2  0  0  6  1  0  0  6  1  1  0  2  1  1
   2  0  0  1  0  1  1  0  0  0  0  0  1  0  3  0  0  0  2  1  0  0  0  1
   0  1  0  0]
 [ 6  9  3 32 33 66 35  4 38  3 15  2  6  3 12  2  7 33  2  4  3  1  1 12
   5  2 17  9  8  1  0  3  4  2  0  2 22  5 11  1 10  3  1  2  0  2  9  0
   6  1  2  1  1  0  2  0  3  1  3  0  4  2  0  3  1  0  0  0  2  0  1  2
   0  0  1  0  1  0  3  3  0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  1
   0  0  1  0]]
Total size of training set
10847
local test distribution:
/data/zikai/aaPFL/pfedlt/util/etf_methods.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sparse_etf = torch.tensor(sparse_etf, requires_grad=True)
[[15 40  0 14 41 14  6  1  2 11  5  0 11 14 29  5  1  2 11 17  5 23  2  0
  18  4 10 32 11  3  3  0  5  4  0  5  2  2  3  0  0  0  1  4  0  0  2  0
   1  4  3  0  0  3  0  4  0  1  2  4  0  0  0  0  0  0  0  0  3  0  0  0
   0  0  0  0  1  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [34 32  3 10 46 14 28 26 22 44  0 36 16  0 11 38 13  1  2  3 12  8 11  1
   0 22  7  0  2  5  0  7  7  9  0  6  0  1  0  1  1  0  3  1  5  7  2  4
   0  0  1  0  0  5  0  2  2  3  0  0  0  0  0  1  2  0  0  1  6  1  0  1
   0  0  1  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  1  0  0  0
   0  0  0  0]
 [66 20 32 18  1  0  6 26  0  5  5  5 35  1 40  7 15 23  3  7  2  2 16  2
   2 11 13  0 19  3  0  8  9  2  0  6  0  0  1  6  0  4  0  2  0  7  0  0
   5  0  0  0  3  0  5  2  0  0  1  2  0  0  1  3  1  1  0  0  1  0  0  0
   0  1  0  0  0  0  0  0  4  1  0  0  0  0  0  0  0  2  1  0  2  0  0  0
   0  0  0  0]
 [54 36  4 10  0  7 16  0  5  6 17  0  0  0  5 12  8  1  1  1 31 27 30 10
  28  3 14  0  3  1  2  0 15  0 20  3  1  5  0  0  9  0  0  3  4  1  3  0
   0  5  0  0  0  0  0  0  1  0  0  0  0  1  0  4  0  0  2  0  0  0  1  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0
   0  1  0  0]
 [19 19 30  2  0 18  0 21 13 28 67  8 43  3  1 19  1  4  7 12  6  2  6  1
   4  0 10  6  2  3  3  0  8  1  2 10  3  0  1  7  1  0 11  6  0  0  2  0
   3  3  0  0  5  0  3  3  0  1  0  6  0  0  0  0  0  0  0  0  0  0  0  2
   0  0  1  0  0  1  0  0  1  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0
   0  0  0  0]
 [ 8  0 38  4  0 35  0  5 51 23 12  0 13  0 34  3 18  3  1  0  7  2  4  4
   0  6  6  0 15  7 17 18  0 13  5 12  0  0  0  5 12 17  1  3  6  2  1  3
   4  2  1  5  0  3  0  6  0  2  1  0  0  0  1  0  1  0  4  2  0  0  1  3
   1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0
   0  0  0  0]
 [23 29  8 13 38  6 83 15 14  5  0  7 19 13 11 17 16 22  8  0  6  1  1  2
  28  0  1  1 11 13  8  2 12  0  0  1  0  1 11  4  0  8  0  2  0  3  0  0
   3  6  2  0  1  1  0  0  0  0  0  1  1  5  0  3  0  0  0  0  2  2  0  0
   0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [ 9 20 35 23  9 20 69 35 21 14  5  7  0 29 14 16 18  0  3 17 30 32  1 21
  21  2  5 12  2  7  9 13  0  7  1  0  5  7 21  0  5  4  6  3  6  0  6  0
   0  0  0  0  0  6  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0
   0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0
   0  1  0  0]
 [22  5 19  1 10  7  0 23 29  2  0 24 20 54  5 29  8 11 43 12  9  0  3 15
  14  8  2  0  3  2  3  6  4  2  2  0 10  4  4  0  3  0  1  6  1  2  0  0
   4  2  2  7  0  0  0  0  1  2  0  0  0  5  3  2  0  1  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  2  0
   0  0  0  0]
 [57 18 19  8  9 79  8 15 21  2  6  5  4 14  6  0  2 13  0  3  2  3 27  7
   1  3  2 11  0 20  9 11  5  1 12  0  0  3  2  6 14  0  0  1  0  7  6  0
   0  1 10  0  0  0  1  1  0  2  0  2  1  1  0  0  1  0  0  1  0  0  0  0
   2  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0
   0  0  0  0]
 [21 51 12 29 66 35  6  2  0 11  8 17  0  6  2 16  4 14  4  4 33  1  6  0
   0  5  3  0  5  0  9 10  0 11  0  7  2  4  2  5  0  0  0  0  3  0  0  4
   0  0  0  4  2  0  1  1  0  0  0  5  0  0  0  0  3  1  0  0  0  0  2  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [ 8 59 28 70  1  0  8  2 10 19 13  5  1 18  1  0  0  0 14  7  0  3  0  0
   3  2 15 11  1  0 20  0  7  0  1  0  0  9  2  2  0  1  6  7  0  5  0  2
   1  2  2  0  0  0  3  1  7  1  0  0  7  0  0  0  1  0  0  0  0  0  0  0
   0  0  0  0  0  0  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   0  0  0  0]
 [ 9 13 54  7 40  0  7 64  1  0  1 35 17 18  2 12  0  5  8 34 12  3  2  0
   0  9  9  1  0  4  9  3  0  7  1  8  1 19  0  8  1  8  0  1  6  1  6  1
   4  3  2  3  6  0  1  0  0  0  5  2  0  0  0  0  0  0  0  0  0  4  0  0
   0  0  0  0  0  1  0  0  0  0  3  0  1  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [16 22 48  3  6  0 11 19 25  2  1 20 11 12  4 23  7  2  0 11  1  3 12 19
   2  0  1 13  3  5  0 10  1  0  4  0  7  6  4  0  2  0  0  2  2  0  0  2
   0  0  0  3  2  5  0  0  0  0  0  0  4  0  1  0  1  0  2  6  0  2  0  0
   0  4  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [ 0  4  1 39 49 11 41 23 30 16  0 12  0 10  3  2 29 41 22 11  6  4  4  3
   0 17 10 20 20  6  0  0  7 15  1 10  4  0  1  5  2  5  0  0  3  1  0  3
   1  0  1  2  6  0  0  4 10  0  4  0  0  0  0  0  0  0  1  0  0  0  0  0
   0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0
   0  0  0  0]
 [23  7  7  3  6  1 12 10 17 73 49 41 28 10 20  6  6  5 23  1  0  0  5 33
  12 28  0  3  5  5  0  4  2  6 10  0  7  4  3  3  0  2 10  3  0  3  0  4
   2  2  0  0  0  3  2  1  1  4  0  0  0  0  9  0  0  3  0  0  1  0  0  0
   0  4  2  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [52 19  2 77  8  6  0  4  0  0 19 11 21  2  2  0  0  8 37 35  1 30  2 17
   0  5  4  0  1  0  2  0  4  2  0 11  1  1  0  4  1  7 12  1  8  0  6 17
   0  0  3  0  0  4  0  0  0  5  4  0  0  0  2  0  0  0  2  0  0  0  1  0
   0  0  0  0  0  0  1  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]
 [ 8 13 14 20  8 29  0 24 10 25 55 23  5 32  2  9 36 11  0  0  3  9 14  0
   2  8  0  0  5  1 10  3  3  5  5  0  5  1  0  0  0  0  0  1  5  0  0  0
   4  0  2  8  0  0  2  0  0  1  2  0  0  0  0  0  0  0  0  0  0  0  4  0
   4  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  2]
 [ 4 15 52 10  5 11  6  4  2  1  2  7  5  1 25  2 20  0  0  0  2  9  7  2
   0  0  0  2  0 23  0  2  0  0 17  0  8  0  1  8  1  1  5  0  0  4  0  1
   0  4  3  0  5  0  7  0  0  0  1  0  0  5  0  0  0  5  0  0  0  1  0  0
   1  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  1  0  0  0  0  0
   0  0  0  0]
 [ 5  8  2 29 30 60 32  3 35  2 13  1  5  2 11  1  6 30  1  3  2  0  0 11
   4  1 15  8  7  0  0  2  3  1  0  1 20  4 10  0  9  2  0  1  0  1  8  0
   5  0  1  0  0  0  1  0  2  0  2  0  3  1  0  2  0  0  0  0  1  0  0  1
   0  0  0  0  0  0  2  2  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]]
Total size of testing set
9097
[453 430 408 390 373 353 339 322 308 289 278 264 254 239 228 217 208 196
 188 178 170 162 153 148 139 134 127 120 115 108 104  99  92  86  81  80
  76  71  66  64  61  59  56  47  49  44  42  41  37  34  33  32  30  30
  26  25  24  22  22  22  16  18  18  15  10  11  12  10  14  10   9   7
   8  10   7   4   5   7   5   5   6   5   5   3   2   2   2   4   3   3
   3   1   3   1   2   1   0   2   0   2]
20
Step 0, Loss 26.808412551879883
Step 100, Loss 16.207275390625
Step 200, Loss 9.392094612121582
Step 300, Loss 5.058143138885498
Step 400, Loss 2.3486483097076416
Step 500, Loss 0.6915582418441772
Step 600, Loss -0.2964928150177002
Step 700, Loss -0.8696840405464172
Step 800, Loss -1.1933913230895996
Step 900, Loss -1.3711750507354736
Step 1000, Loss -1.466719150543213
Step 1100, Loss -1.5172274112701416
Step 1200, Loss -1.5438002347946167
Step 1300, Loss -1.557953119277954
Step 1400, Loss -1.5657343864440918
Step 1500, Loss -1.5701546669006348
Step 1600, Loss -1.5729793310165405
Step 1700, Loss -1.574595332145691
Step 1800, Loss -1.575655221939087
Step 1900, Loss -1.5763546228408813
Step 2000, Loss -1.576837182044983
Step 2100, Loss -1.576935052871704
Step 2200, Loss -1.5771434307098389
Step 2300, Loss -1.5771251916885376
Step 2400, Loss -1.5771111249923706
Step 2500, Loss -1.5770262479782104
Step 2600, Loss -1.5770690441131592
Step 2700, Loss -1.5769929885864258
Step 2800, Loss -1.5769795179367065
Step 2900, Loss -1.5768870115280151
Step 3000, Loss -1.5768505334854126
Step 3100, Loss -1.5768224000930786
Step 3200, Loss -1.5768464803695679
Step 3300, Loss -1.5767252445220947
Step 3400, Loss -1.5766639709472656
Step 3500, Loss -1.5766503810882568
Step 3600, Loss -1.5765444040298462
Step 3700, Loss -1.5766068696975708
Step 3800, Loss -1.5764766931533813
Step 3900, Loss -1.576399564743042
Step 4000, Loss -1.5764796733856201
Step 4100, Loss -1.5765269994735718
Step 4200, Loss -1.5763708353042603
Step 4300, Loss -1.5762498378753662
Step 4400, Loss -1.5762797594070435
Step 4500, Loss -1.5763030052185059
Step 4600, Loss -1.5762525796890259
Step 4700, Loss -1.5762146711349487
Step 4800, Loss -1.5761213302612305
Step 4900, Loss -1.5761514902114868
Step 5000, Loss -1.576151728630066
Step 5100, Loss -1.5761699676513672
Step 5200, Loss -1.5761200189590454
Step 5300, Loss -1.5760738849639893
Step 5400, Loss -1.5760204792022705
Step 5500, Loss -1.5760326385498047
Step 5600, Loss -1.576002597808838
Step 5700, Loss -1.5760140419006348
Step 5800, Loss -1.5759795904159546
Step 5900, Loss -1.5760722160339355
Step 6000, Loss -1.575997233390808
Step 6100, Loss -1.5759315490722656
Step 6200, Loss -1.5759752988815308
Step 6300, Loss -1.5759637355804443
Step 6400, Loss -1.5758576393127441
Step 6500, Loss -1.5759222507476807
Step 6600, Loss -1.5758655071258545
Step 6700, Loss -1.5760176181793213
Step 6800, Loss -1.5758776664733887
Step 6900, Loss -1.575880527496338
Step 7000, Loss -1.5759073495864868
Step 7100, Loss -1.5759243965148926
Step 7200, Loss -1.5758693218231201
Step 7300, Loss -1.5758510828018188
Step 7400, Loss -1.575908899307251
Step 7500, Loss -1.5758647918701172
Step 7600, Loss -1.5758920907974243
Step 7700, Loss -1.5757967233657837
Step 7800, Loss -1.5758782625198364
Step 7900, Loss -1.575906753540039
Step 8000, Loss -1.5758904218673706
Step 8100, Loss -1.575901985168457
Step 8200, Loss -1.5759364366531372
Step 8300, Loss -1.5759589672088623
Step 8400, Loss -1.5759321451187134
Step 8500, Loss -1.5759546756744385
Step 8600, Loss -1.57591712474823
Step 8700, Loss -1.5758155584335327
Step 8800, Loss -1.575975775718689
Step 8900, Loss -1.5759137868881226
Step 9000, Loss -1.5759090185165405
Step 9100, Loss -1.5759620666503906
Step 9200, Loss -1.575888991355896
Step 9300, Loss -1.5758802890777588
Step 9400, Loss -1.5758943557739258
Step 9500, Loss -1.5759142637252808
Step 9600, Loss -1.5758599042892456
Step 9700, Loss -1.5757946968078613
Step 9800, Loss -1.5758644342422485
Step 9900, Loss -1.5758458375930786
Angle Mean: 90.5778579711914, Angle Variance: 0.0445784367620945
Norm Mean: 0.10023948550224304, Norm Variance: 2.0799386657444074e-09
  0%|          | 0/500 [00:00<?, ?it/s]