nohup: ignoring input
./temp/fl_acc_cifar100_resnet34_cons_frac0.2_iidFalse_iter500_ep5_lr0.03_N20_100_seed3407_p1_dirichlet1.0_IF0.02_LossCE.txt
Files already downloaded and verified
[500, 480, 462, 444, 426, 410, 394, 379, 364, 350, 336, 323, 311, 299, 287, 276, 265, 255, 245, 235, 226, 218, 209, 201, 193, 186, 178, 172, 165, 158, 152, 146, 141, 135, 130, 125, 120, 115, 111, 107, 102, 98, 95, 91, 87, 84, 81, 78, 75, 72, 69, 66, 64, 61, 59, 56, 54, 52, 50, 48, 46, 44, 43, 41, 39, 38, 36, 35, 34, 32, 31, 30, 29, 27, 26, 25, 24, 23, 22, 22, 21, 20, 19, 18, 18, 17, 16, 16, 15, 14, 14, 13, 13, 12, 12, 11, 11, 10, 10, 10]
12608
Files already downloaded and verified
Into non-iid sampling
clients_sizes:[570, 712, 662, 720, 618, 725, 737, 505, 658, 678, 817, 646, 671, 616, 477, 642, 488, 544, 629, 493]
training set distribution:
[[17 45  5 34 11 10  4 31  2 14  0 17 14 26  7  9 19 20 19 10  4  0 18  3
  12  4  4 23 24  1  0  0 14  1 13  8  4  5  2  1  4  8  9 11  0  4  0  9
   2  1  1  1  2  4  3 10  0  2  5  2  6  0  1  3  2  3  2  0  0  0  1  1
   0  0  0  0  0  0  0  4  0  1  0  0  0  3  2  2  0  0  0  0  0  0  2  0
   2  0  2  0]
 [37 35 37 79  7 58  5 14 23  9  6 25 24  3 10 15 21  7 18 20  2  2  7 19
   6 20 15  2 14  2 24  0  8  2 15  4 20  7  0  0  0  3  1  5  2  1  3  0
   1  3  6  4  2  4  2  1  1  1  1  0  0  2  1  0  0  0  4  0  4  2  6  0
   4  2  4  0  2  0  0  1  0  0  1  0  3  1  0  0  0  0  0  0  0  3  0  3
   6  0  0  0]
 [72 23 27  5  4  5 79  4 10  6 65 13 13  2 43 10  0  8 18 14  6  0 16  2
   0  3 24  2  0  0  1  3 15 18 11  3  2  2  6  4  3  8  2  2  1  0 11  0
   2  1  0  5  0  0  2  7  0  1  1  5  6  9  2  0  3  6  0  2  4  1  2  1
   2  0  3  7  2  1  1  0  0  0  2  2  2  1  0  3  2  1  1  1  1  2  1  0
   0  1  0  0]
 [59 40  8  2  0 13  2 18 30  1  0  1 21  2 62  5 36 36 13 75  1 27  1 33
   8 17  3 11  2  2  2 15  6 19  4  5  7  1  3  0  4  5  0  5  2  0  0  3
   5 21  0  1  2  1  5  7  2  0  1  2  0  7  1  1  1  6  0  0  1  2  1  0
   0  2  4  2  2  0  1  3  2  4  2  0  0  1  2  1  0  2  5  1  2  0  1  2
   1  2  1  0]
 [21 21 45 49 16  0  3 42 58  4  1  2 10  7  4  6 24  4 10 11 33 10 16  2
   1 19  6  6  0  5  3  4  0  0  4 14  1  0  1  0  6  1  4 16  7  3  9 16
   2  0  4  2  0  5  1  3 15  2  2  9  7  2  0  5  3  2  0  0  0  1  1  2
   0  0  0  5  5  1  1  2  0  5  0  1  0  0  0  0  0  1  0  0  0  0  0  2
   0  1  0  1]
 [ 9  1 26  7 48 50 14  0  2  4 14 46 37 57 12 20  4  7  4  5 24 60  9  7
   1 10  9 23  7  7  5  5 12 14  5  4  2  1 17 15  4 15  6  2  1  6  0  1
   1  6 12  6  5  0  0  1  3  0  0  2  1  1  0  1  1  3  3  8  1  2  4  2
   0  0  0  4  0  1  0  4  0  1  0  0  2  1  1  0  1  0  0  2  0  0  0  0
   0  0  0  6]
 [25 32 22 89 14  0 12 45  7 17 42 25  1  2 16 31  5 23  3  5 21 17 13 27
  35 11  4  6  9  2  1  9  3  8  3  5  8  2 13  1  3  0  8 14  5  0  2  3
   3  3  3  0  9 12  2  1 11  2  6  1  4  0  1  1  3  1  3  0  0  1  0  1
   1  0  1  1  0  1  1  0  3  1  1  1  1  2  1  3  0  0  0  1  0  0  0  0
   0  0  0  1]
 [10 22  5 20 11 10  6  8 35 26 32 27  5 11  2  5 12 11 12  0  6  1  0 10
   4  1  0  4 13 11  2  7  9  0  3  8 19  8  9  1  1  0  7  1  7 32  1  1
   0 11  2  4  4  1  3  2  0  0  2  0  0  1  0  0  1  3  5  0  0  1  0  1
   1  0  0  0  0  2  7  0  1  2  1  1  3  0  4  1  0  0  2  1  0  1  0  0
   0  0  0  1]
 [24  6 36 10 28  2 48 32 34 26 19 32 26  4  3  7  1  3 25  5 31  4 16  5
   0  1  3 12 13  4  4  6  1  1  2 12  0 12  2 36 12  9  4  2  5 11  7 11
   3  0  1  6  2  0  2  5  0  2  0  5  1  1  8  0  0  3  0  3  0  0  4  4
   0  0  0  0  0  0  1  1  0  0  3  0  2  0  0  0  0  0  1  0  0  2  1  0
   0  0  0  0]
 [62 20 59 36  7  4  3 34  9 14 32  1  9  0 24  4 45  4 18  9  2 20 11 56
   2 16  1  1  2  4  6  0  0 10 13  3  5 10  7  2  2  0  1  1  9  2 12  8
  11  0  0 12  2  1  3  6  5  3  6  4  0  1  0  0  1  1  1  1  1  0  0  0
   2  2  2  2  0  0  1  0  0  1  1  1  0  0  2  0  0  1  2  0  0  0  0  0
   1  1  0  0]
 [23 56 65 22  6 40 20 35 12 38  6 16  5 60 23 12 31  7 14  3 13 19  3  1
   6 17  8  2 17 18  4 17  8  1  3  3  2 17  7  7 21 11  5  0  3  1  5  3
   7  5 10  1  2  7  9  6  3  2  7  0  0  0  3  2  2  1  1  0 10  2  0  2
   1  0  2  0  0  1  2  0  0  0  1  0  0  0  2  0  0  0  2  0  1  0  3  1
   0  1  1  1]
 [ 9 64  2 14 27 66  5 25 27 33 27  9  6 35 20 11  2 21 12  1  2  6 10  5
   7  3  9  5  3 14 16 15  1  7  1 12  6  0  8  4  1  0 13  5 12  0  5  4
   0  0  0  0  1  5  5  1  0  0  0  6  2  2  4  0  2  0  0  1  1  2  2  0
   0  3  0  0  0  3  2  0  2  1  3  1  1  0  0  0  1  1  0  0  2  1  0  0
   0  1  0  0]
 [10 15 10 29  2 52 53 13 13  5 36  5 30  8  7  6 13  0 23 16 13  7 14  1
  26 15  8  0 14 40  1 25  6  1 15  3 19  0  0  4  7 10  0  1  6  4  1  2
   3  0  1  0  1  3  3  0  1  5  7  3  9  1  2  2  1  0  2  7  1  0  1  1
   0  3  1  1  1  4  0  1  3  1  1  1  0  1  0  3  0  0  0  0  0  1  1  1
   0  1  3  0]
 [18 24  5  4 23  0 68 22 13 46 10 12  1 25  0 11 29  2  9  4 10  3 22  2
  35 10  5  1  5  5  3  2 16 19 13  4  0  1  0  2 10  5  9  1 11  2  0  3
   1  5  3  6  2  2  2  2  2  5  1  3  1  4  4  2  0  0  1  1  6  0  1  1
   3  9  4  0  3  0  1  0  2  1  0  1  2  2  0  0  1  0  0  3  2  1  0  0
   0  0  1  0]
 [ 1  6 14 24 45  1 39  1  1 18  1  3 16 11  6 38  3 22  3 10 10  4  2 14
   1  6  4  9  1  3  6  0 13  3  4  2  4  1  4  0  1 17  0  2  2  1  7  3
   5  1  6  1  9  0  5  2  1  5  4  1  0  0  2  4  0  0  8  6  1  3  3  4
   3  1  0  0  0  1  0  0  0  1  1  1  0  0  1  1  3  5  0  0  0  0  0  0
   0  1  0  0]
 [26  8 52  0 14 31  1 12  5 34 23  8  3 14  2 24  1 32 17  3 19  0 12  1
  21  2 10 21 15 13  3  7  6 15  1 13 17 15  4  3  1  4 10  0  2  3  4  0
   0  7  4 10  5  0  5  1  0  8  4  0  2  2  1  9  0  0  0  1  2  9  0  2
   6  3  0  2  2  4  0  1  5  0  0  5  1  4  0  0  0  0  0  1  0  0  1  1
   0  0  2  0]
 [57 21 15  5  7  3  8  5  0  0  0 21  6 17  0 14  5  9  4  5  1 16 15  6
   5  3 53  2  2 10 44  4  0  1  1  5  0 19  1  0  1  0  5  0  3  5  2  2
   4  4  2  0  6  3  0  0  0  3  0  5  2  7  5  2  0  4  0  3  2  1  2  4
   0  0  0  0  0  0  0  4  2  1  0  2  0  1  0  2  0  1  1  3  0  1  2  0
   0  1  0  0]
 [ 9 15 14 10 19 18 15  5 30 37  0 15 59  2 22 20  9 14 12 24 14  1  1  1
   2  7  9  0  2  0  9  1  5  8  6  4  2 10  6  7  2  1  1  1  0  2 11  6
   2  0 11  1  7  0  2  1  2  1  0  0  3  1  1  2 18  0  4  1  0  2  2  1
   0  0  1  0  0  2  2  0  0  0  0  1  0  0  1  0  2  1  0  0  3  0  0  0
   1  0  0  0]
 [ 5 17  0  1 80 21  7 13 10 15 22 39 24 11 17 13  0  4  6  5 10 21 12  1
   8 14  2 37 13  8  1 18  6  1  5  7  0  2 14 13 14  0  3 22  1  6  0  2
  20  4  2  1  1  6  4  0  5  3  0  0  0  2  7  4  0  1  1  1  0  0  0  1
   1  2  0  0  2  2  2  0  0  0  0  0  0  0  0  0  4  0  0  0  2  0  0  0
   0  0  0  0]
 [ 6  9 15  4 57 26  2 20 43  3  0  6  1  2  7 15  5 21  5 10  4  0 11  5
  13  7  1  5  9  9 17  8 12  6  8  6  2  2  7  7  5  1  7  0  8  1  1  1
   3  0  1  5  2  7  1  0  3  7  3  0  2  1  0  3  1  4  1  0  0  3  1  2
   5  0  4  1  5  0  0  1  1  0  2  0  1  0  0  0  1  1  0  0  0  0  0  1
   0  0  0  0]]
Total size of training set
12608
local test distribution:
/data/zikai/aaPFL/pfedlt/util/etf_methods.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sparse_etf = torch.tensor(sparse_etf, requires_grad=True)
[[13 35  3 26  8  7  3 24  1 11  0 13 11 20  5  7 15 15 15  7  3  0 14  2
   9  3  3 18 19  0  0  0 11  0 10  6  3  3  1  0  3  6  7  8  0  3  0  7
   1  0  0  0  1  3  2  7  0  1  3  1  4  0  0  2  1  2  1  0  0  0  0  0
   0  0  0  0  0  0  0  3  0  0  0  0  0  2  1  1  0  0  0  0  0  0  1  0
   1  0  1  0]
 [29 27 29 62  5 46  3 11 18  7  4 19 19  2  7 11 16  5 14 15  1  1  5 15
   4 15 11  1 11  1 19  0  6  1 11  3 15  5  0  0  0  2  0  3  1  0  2  0
   0  2  4  3  1  3  1  0  0  0  0  0  0  1  0  0  0  0  3  0  3  1  4  0
   3  1  3  0  1  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  2  0  2
   4  0  0  0]
 [57 18 21  3  3  3 62  3  7  4 51 10 10  1 34  7  0  6 14 11  4  0 12  1
   0  2 19  1  0  0  0  2 11 14  8  2  1  1  4  3  2  6  1  1  0  0  8  0
   1  0  0  3  0  0  1  5  0  0  0  3  4  7  1  0  2  4  0  1  3  0  1  0
   1  0  2  5  1  0  0  0  0  0  1  1  1  0  0  2  1  0  0  0  0  1  0  0
   0  0  0  0]
 [46 31  6  1  0 10  1 14 23  0  0  0 16  1 49  3 28 28 10 59  0 21  0 26
   6 13  2  8  1  1  1 11  4 15  3  3  5  0  2  0  3  3  0  3  1  0  0  2
   3 16  0  0  1  0  3  5  1  0  0  1  0  5  0  0  0  4  0  0  0  1  0  0
   0  1  3  1  1  0  0  2  1  3  1  0  0  0  1  0  0  1  3  0  1  0  0  1
   0  1  0  0]
 [16 16 35 38 12  0  2 33 46  3  0  1  7  5  3  4 19  3  7  8 26  7 12  1
   0 15  4  4  0  3  2  3  0  0  3 11  0  0  0  0  4  0  3 12  5  2  7 12
   1  0  3  1  0  3  0  2 11  1  1  7  5  1  0  3  2  1  0  0  0  0  0  1
   0  0  0  3  3  0  0  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  1
   0  0  0  0]
 [ 7  0 20  5 38 39 11  0  1  3 11 36 29 45  9 15  3  5  3  3 19 47  7  5
   0  7  7 18  5  5  3  3  9 11  3  3  1  0 13 11  3 11  4  1  0  4  0  0
   0  4  9  4  3  0  0  0  2  0  0  1  0  0  0  0  0  2  2  6  0  1  3  1
   0  0  0  3  0  0  0  3  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0
   0  0  0  4]
 [19 25 17 70 11  0  9 35  5 13 33 19  0  1 12 24  3 18  2  3 16 13 10 21
  27  8  3  4  7  1  0  7  2  6  2  3  6  1 10  0  2  0  6 11  3  0  1  2
   2  2  2  0  7  9  1  0  8  1  4  0  3  0  0  0  2  0  2  0  0  0  0  0
   0  0  0  0  0  0  0  0  2  0  0  0  0  1  0  2  0  0  0  0  0  0  0  0
   0  0  0  0]
 [ 7 17  3 15  8  7  4  6 27 20 25 21  3  8  1  3  9  8  9  0  4  0  0  7
   3  0  0  3 10  8  1  5  7  0  2  6 15  6  7  0  0  0  5  0  5 25  0  0
   0  8  1  3  3  0  2  1  0  0  1  0  0  0  0  0  0  2  3  0  0  0  0  0
   0  0  0  0  0  1  5  0  0  1  0  0  2  0  3  0  0  0  1  0  0  0  0  0
   0  0  0  0]
 [19  4 28  7 22  1 38 25 26 20 15 25 20  3  2  5  0  2 19  3 24  3 12  3
   0  0  2  9 10  3  3  4  0  0  1  9  0  9  1 28  9  7  3  1  3  8  5  8
   2  0  0  4  1  0  1  3  0  1  0  3  0  0  6  0  0  2  0  2  0  0  3  3
   0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  1  0  0
   0  0  0  0]
 [49 15 46 28  5  3  2 26  7 11 25  0  7  0 19  3 35  3 14  7  1 15  8 44
   1 12  0  0  1  3  4  0  0  7 10  2  3  7  5  1  1  0  0  0  7  1  9  6
   8  0  0  9  1  0  2  4  3  2  4  3  0  0  0  0  0  0  0  0  0  0  0  0
   1  1  1  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0
   0  0  0  0]
 [18 44 51 17  4 31 15 27  9 30  4 12  3 47 18  9 24  5 11  2 10 15  2  0
   4 13  6  1 13 14  3 13  6  0  2  2  1 13  5  5 16  8  3  0  2  0  3  2
   5  3  7  0  1  5  7  4  2  1  5  0  0  0  2  1  1  0  0  0  7  1  0  1
   0  0  1  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  2  0
   0  0  0  0]
 [ 7 50  1 11 21 52  3 19 21 26 21  7  4 27 15  8  1 16  9  0  1  4  7  3
   5  2  7  3  2 11 12 11  0  5  0  9  4  0  6  3  0  0 10  3  9  0  3  3
   0  0  0  0  0  3  3  0  0  0  0  4  1  1  3  0  1  0  0  0  0  1  1  0
   0  2  0  0  0  2  1  0  1  0  2  0  0  0  0  0  0  0  0  0  1  0  0  0
   0  0  0  0]
 [ 7 11  7 23  1 41 42 10 10  3 28  3 23  6  5  4 10  0 18 12 10  5 11  0
  20 11  6  0 11 31  0 19  4  0 11  2 15  0  0  3  5  7  0  0  4  3  0  1
   2  0  0  0  0  2  2  0  0  3  5  2  7  0  1  1  0  0  1  5  0  0  0  0
   0  2  0  0  0  3  0  0  2  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0
   0  0  2  0]
 [14 19  3  3 18  0 53 17 10 36  7  9  0 19  0  8 23  1  7  3  7  2 17  1
  27  7  3  0  3  3  2  1 12 15 10  3  0  0  0  1  7  3  7  0  8  1  0  2
   0  3  2  4  1  1  1  1  1  3  0  2  0  3  3  1  0  0  0  0  4  0  0  0
   2  7  3  0  2  0  0  0  1  0  0  0  1  1  0  0  0  0  0  2  1  0  0  0
   0  0  0  0]
 [ 0  4 11 19 35  0 30  0  0 14  0  2 12  8  4 30  2 17  2  7  7  3  1 11
   0  4  3  7  0  2  4  0 10  2  3  1  3  0  3  0  0 13  0  1  1  0  5  2
   3  0  4  0  7  0  3  1  0  3  3  0  0  0  1  3  0  0  6  4  0  2  2  3
   2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  3  0  0  0  0  0  0
   0  0  0  0]
 [20  6 41  0 11 24  0  9  3 26 18  6  2 11  1 19  0 25 13  2 15  0  9  0
  16  1  7 16 11 10  2  5  4 11  0 10 13 11  3  2  0  3  7  0  1  2  3  0
   0  5  3  7  3  0  3  0  0  6  3  0  1  1  0  7  0  0  0  0  1  7  0  1
   4  2  0  1  1  3  0  0  3  0  0  3  0  3  0  0  0  0  0  0  0  0  0  0
   0  0  1  0]
 [45 16 11  3  5  2  6  3  0  0  0 16  4 13  0 11  3  7  3  3  0 12 11  4
   3  2 42  1  1  7 34  3  0  0  0  3  0 15  0  0  0  0  3  0  2  3  1  1
   3  3  1  0  4  2  0  0  0  2  0  3  1  5  3  1  0  3  0  2  1  0  1  3
   0  0  0  0  0  0  0  3  1  0  0  1  0  0  0  1  0  0  0  2  0  0  1  0
   0  0  0  0]
 [ 7 11 11  7 15 14 11  3 23 29  0 11 46  1 17 15  7 11  9 19 11  0  0  0
   1  5  7  0  1  0  7  0  3  6  4  3  1  7  4  5  1  0  0  0  0  1  8  4
   1  0  8  0  5  0  1  0  1  0  0  0  2  0  0  1 14  0  3  0  0  1  1  0
   0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  1  0  0  0  2  0  0  0
   0  0  0  0]
 [ 3 13  0  0 63 16  5 10  7 11 17 30 19  8 13 10  0  3  4  3  7 16  9  0
   6 11  1 29 10  6  0 14  4  0  3  5  0  1 11 10 11  0  2 17  0  4  0  1
  15  3  1  0  0  4  3  0  3  2  0  0  0  1  5  3  0  0  0  0  0  0  0  0
   0  1  0  0  1  1  1  0  0  0  0  0  0  0  0  0  3  0  0  0  1  0  0  0
   0  0  0  0]
 [ 4  7 11  3 45 20  1 15 34  2  0  4  0  1  5 11  3 16  3  7  3  0  8  3
  10  5  0  3  7  7 13  6  9  4  6  4  1  1  5  5  3  0  5  0  6  0  0  0
   2  0  0  3  1  5  0  0  2  5  2  0  1  0  0  2  0  3  0  0  0  2  0  1
   3  0  3  0  3  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0]]
Total size of testing set
9142
[387 369 355 341 330 316 301 290 278 269 259 244 235 227 219 207 201 194
 186 174 169 164 155 147 142 136 133 126 123 116 110 107 102  97  92  90
  87  80  80  77  70  69  66  61  58  57  55  53  49  49  45  41  40  40
  36  33  34  31  31  30  29  25  25  25  23  23  21  20  19  17  16  14
  16  17  16  14  13  11   9  12  11   7   7   5   8   7   7   8   7   4
   6   5   6   4   4   4   5   1   4   4]
20
Step 0, Loss 26.76883888244629
Step 100, Loss 16.187068939208984
Step 200, Loss 9.382832527160645
Step 300, Loss 5.055148601531982
Step 400, Loss 2.348543405532837
Step 500, Loss 0.692234992980957
Step 600, Loss -0.29607653617858887
Step 700, Loss -0.8693376779556274
Step 800, Loss -1.1926515102386475
Step 900, Loss -1.3705075979232788
Step 1000, Loss -1.4661873579025269
Step 1100, Loss -1.5169271230697632
Step 1200, Loss -1.5437190532684326
Step 1300, Loss -1.557974934577942
Step 1400, Loss -1.5659517049789429
Step 1500, Loss -1.5704904794692993
Step 1600, Loss -1.573125958442688
Step 1700, Loss -1.5747277736663818
Step 1800, Loss -1.5757120847702026
Step 1900, Loss -1.5763412714004517
Step 2000, Loss -1.5767804384231567
Step 2100, Loss -1.5770219564437866
Step 2200, Loss -1.5771013498306274
Step 2300, Loss -1.5772035121917725
Step 2400, Loss -1.5771194696426392
Step 2500, Loss -1.577151894569397
Step 2600, Loss -1.5771135091781616
Step 2700, Loss -1.577057957649231
Step 2800, Loss -1.5770050287246704
Step 2900, Loss -1.5768762826919556
Step 3000, Loss -1.5768860578536987
Step 3100, Loss -1.576900601387024
Step 3200, Loss -1.5768897533416748
Step 3300, Loss -1.5767781734466553
Step 3400, Loss -1.5767290592193604
Step 3500, Loss -1.5766775608062744
Step 3600, Loss -1.5766264200210571
Step 3700, Loss -1.576583981513977
Step 3800, Loss -1.5764449834823608
Step 3900, Loss -1.576449990272522
Step 4000, Loss -1.5763963460922241
Step 4100, Loss -1.576299786567688
Step 4200, Loss -1.5762659311294556
Step 4300, Loss -1.5763847827911377
Step 4400, Loss -1.5762300491333008
Step 4500, Loss -1.5762639045715332
Step 4600, Loss -1.576174020767212
Step 4700, Loss -1.5762451887130737
Step 4800, Loss -1.5761516094207764
Step 4900, Loss -1.5762070417404175
Step 5000, Loss -1.5761334896087646
Step 5100, Loss -1.576155424118042
Step 5200, Loss -1.57606041431427
Step 5300, Loss -1.5760587453842163
Step 5400, Loss -1.576062560081482
Step 5500, Loss -1.5760592222213745
Step 5600, Loss -1.5760787725448608
Step 5700, Loss -1.5759339332580566
Step 5800, Loss -1.5759291648864746
Step 5900, Loss -1.5760201215744019
Step 6000, Loss -1.576002836227417
Step 6100, Loss -1.5759581327438354
Step 6200, Loss -1.5760772228240967
Step 6300, Loss -1.575836420059204
Step 6400, Loss -1.5759531259536743
Step 6500, Loss -1.5758941173553467
Step 6600, Loss -1.5758874416351318
Step 6700, Loss -1.5759799480438232
Step 6800, Loss -1.5758577585220337
Step 6900, Loss -1.5759598016738892
Step 7000, Loss -1.5759679079055786
Step 7100, Loss -1.5758283138275146
Step 7200, Loss -1.5758998394012451
Step 7300, Loss -1.575844407081604
Step 7400, Loss -1.575914978981018
Step 7500, Loss -1.5758090019226074
Step 7600, Loss -1.5759462118148804
Step 7700, Loss -1.5759251117706299
Step 7800, Loss -1.5758901834487915
Step 7900, Loss -1.5759565830230713
Step 8000, Loss -1.5758765935897827
Step 8100, Loss -1.575793743133545
Step 8200, Loss -1.5758461952209473
Step 8300, Loss -1.5758836269378662
Step 8400, Loss -1.5759183168411255
Step 8500, Loss -1.5759259462356567
Step 8600, Loss -1.5759038925170898
Step 8700, Loss -1.575925350189209
Step 8800, Loss -1.5758354663848877
Step 8900, Loss -1.5759680271148682
Step 9000, Loss -1.5759809017181396
Step 9100, Loss -1.5758079290390015
Step 9200, Loss -1.5759170055389404
Step 9300, Loss -1.5758870840072632
Step 9400, Loss -1.5759676694869995
Step 9500, Loss -1.5758702754974365
Step 9600, Loss -1.5758934020996094
Step 9700, Loss -1.575806736946106
Step 9800, Loss -1.5759434700012207
Step 9900, Loss -1.5759103298187256
Angle Mean: 90.57786560058594, Angle Variance: 0.04413813352584839
Norm Mean: 0.10023734718561172, Norm Variance: 2.272467325425964e-09
  0%|          | 0/500 [00:00<?, ?it/s]